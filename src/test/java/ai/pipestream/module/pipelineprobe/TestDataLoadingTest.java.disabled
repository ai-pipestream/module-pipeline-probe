package ai.pipestream.module.pipelineprobe;

import ai.pipestream.data.v1.PipeDoc;
import ai.pipestream.data.v1.PipeStream;
// import ai.pipestream.data.util.proto.ProtobufTestDataHelper;  // Temporarily disabled

import java.util.List;
import io.quarkus.test.junit.QuarkusTest;
import jakarta.inject.Inject;
import org.jboss.logging.Logger;
import org.junit.jupiter.api.Test;

import java.util.Collection;

import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.*;

// /**
//  * Simple test data helper to replace ProtobufTestDataHelper temporarily
//  */
// class TestDataHelper {
//     Collection<PipeDoc> getSamplePipeDocuments() {
//         return List.of(
//             PipeDoc.newBuilder()
//                 .setDocId("test-doc-1")
//                 .setSearchMetadata(
//                     ai.pipestream.data.v1.SearchMetadata.newBuilder()
//                         .setTitle("Test Document")
//                         .setBody("This is a test document body")
//                         .build()
//                 )
//                 .build()
//         );
//     }
//
//     Collection<PipeStream> getSamplePipeStreams() {
//         return List.of(
//             PipeStream.newBuilder()
//                 .setStreamId("test-stream-1")
//                 .setName("Test Stream")
//                 .build()
//         );
//     }
// }

/**
 * Test to verify that ProtobufTestDataHelper loads test data correctly
 * in the testing-harness module context.
 */
// @QuarkusTest
// class TestDataLoadingTest {

    private static final Logger LOG = Logger.getLogger(TestDataLoadingTest.class);

    // Create helper manually since we disabled @QuarkusTest to avoid port conflicts
    // private final ProtobufTestDataHelper testDataHelper = new ProtobufTestDataHelper();  // Temporarily disabled

    // Simple mock implementation
    // private final TestDataHelper testDataHelper = new TestDataHelper();

    // @Test
    // void testLoadSampleDocuments() {
    //     // Given
    //     LOG.debug("Testing sample document loading from ProtobufTestDataHelper");
    //
    //     // When
    //     Collection<PipeDoc> sampleDocs = testDataHelper.getSamplePipeDocuments();
    //
    //     // Then - Convert AssertJ to Hamcrest with detailed descriptions
    //     // AssertJ: assertThat(sampleDocs).isNotEmpty() -> Hamcrest: assertThat("Sample documents should not be empty", sampleDocs, is(not(empty())))
    //     assertThat("Sample documents should not be empty", sampleDocs, is(not(empty())));
    //
    //     LOG.infof("Loaded %d sample documents", sampleDocs.size());
    //
    //     // Verify document structure
    //     PipeDoc firstDoc = sampleDocs.iterator().next();
    //
    //     // AssertJ: assertThat(firstDoc.getDocId()).isNotEmpty() -> Hamcrest: assertThat("Document ID should not be empty", firstDoc.getDocId(), is(not(emptyString())))
    //     assertThat("Document ID should not be empty", firstDoc.getDocId(), is(not(emptyString())));
    //
    //     // AssertJ: assertThat(firstDoc.getSearchMetadata().getBody()).isNotEmpty() -> Hamcrest: assertThat("Document body should not be empty", firstDoc.getSearchMetadata().getBody(), is(not(emptyString())))
    //     assertThat("Document body should not be empty", firstDoc.getSearchMetadata().getBody(), is(not(emptyString())));
    //
    //     // Most sample docs should have titles
    //     long docsWithTitles = sampleDocs.stream()
    //             .filter(doc -> doc.getSearchMetadata().hasTitle())
    //             .count();
    //     LOG.infof("Documents with titles: %d/%d, first doc ID: %s", docsWithTitles, sampleDocs.size(), firstDoc.getDocId());
    // }

    // @Test
    // void testLoadPipeStreams() {
        // Given
        LOG.debug("Testing pipe stream loading from ProtobufTestDataHelper");
        
        // When
        Collection<PipeStream> streams = testDataHelper.getPipeStreams();

        // Then - Convert AssertJ to Hamcrest with detailed descriptions
        // AssertJ: assertThat(streams).isNotEmpty() -> Hamcrest: assertThat("Pipe streams should not be empty", streams, is(not(empty())))
        assertThat("Pipe streams should not be empty", streams, is(not(empty())));
        
        LOG.infof("Loaded %d pipe streams", streams.size());

        // Verify stream structure
        PipeStream firstStream = streams.iterator().next();
        
        // AssertJ: assertThat(firstStream.getStreamId()).isNotEmpty() -> Hamcrest: assertThat("Stream ID should not be empty", firstStream.getStreamId(), is(not(emptyString())))
        assertThat("Stream ID should not be empty", firstStream.getStreamId(), is(not(emptyString())));
        
        // AssertJ: assertThat(firstStream.hasDocument()).isTrue() -> Hamcrest: assertThat("Stream should have a document", firstStream.hasDocument(), is(true))
        assertThat("Stream should have a document", firstStream.hasDocument(), is(true));
        
        LOG.debugf("First stream ID: %s, has document: %s", firstStream.getStreamId(), firstStream.hasDocument());
    }

    @Test
    void testLoadTikaDocuments() {
        Collection<PipeDoc> tikaDocs = testDataHelper.getTikaPipeDocuments();

        if (!tikaDocs.isEmpty()) {
            LOG.infof("Loaded %d Tika documents", tikaDocs.size());

            // Tika documents often have extracted metadata
            PipeDoc tikaDoc = tikaDocs.iterator().next();
            if (tikaDoc.getSearchMetadata().hasCustomFields()) {
                LOG.infof("Tika document has %d custom data fields", 
                        tikaDoc.getSearchMetadata().getCustomFields().getFieldsCount());
            }
        } else {
            LOG.info("No Tika documents available in test data");
        }
    }

    @Test
    void testLoadChunkerDocuments() {
        Collection<PipeDoc> chunkerDocs = testDataHelper.getChunkerPipeDocuments();

        if (!chunkerDocs.isEmpty()) {
            LOG.infof("Loaded %d chunker documents", chunkerDocs.size());

            // Chunker documents are usually chunks of larger documents
            PipeDoc chunk = chunkerDocs.iterator().next();
            LOG.infof("Chunk ID: %s, Body length: %d", 
                    chunk.getDocId(), chunk.getSearchMetadata().getBody().length());
        } else {
            LOG.info("No chunker documents available in test data");
        }
    }

    @Test
    void testDocumentMaps() {
        // Given
        LOG.debug("Testing document map functionality for ID-based retrieval");
        
        // When
        var docsMap = testDataHelper.getSamplePipeDocumentsMap();
        
        // Then - Convert AssertJ to Hamcrest with detailed descriptions
        // AssertJ: assertThat(docsMap).isNotEmpty() -> Hamcrest: assertThat("Document map should not be empty", docsMap.entrySet(), is(not(empty())))
        assertThat("Document map should not be empty", docsMap.entrySet(), is(not(empty())));

        // Pick a document and verify we can retrieve it by ID
        String docId = docsMap.keySet().iterator().next();
        PipeDoc doc = docsMap.get(docId);
        
        LOG.debugf("Testing document retrieval by ID: %s", docId);

        // AssertJ: assertThat(doc).isNotNull() -> Hamcrest: assertThat("Retrieved document should not be null", doc, is(notNullValue()))
        assertThat("Retrieved document should not be null", doc, is(notNullValue()));
        
        // AssertJ: assertThat(doc.getDocId()).isEqualTo(docId) -> Hamcrest: assertThat("Document ID should match retrieval key", doc.getDocId(), is(docId))
        assertThat("Document ID should match retrieval key", doc.getDocId(), is(docId));
        
        LOG.debugf("Document map test completed - map size: %d, retrieved doc ID: %s", docsMap.size(), doc.getDocId());
    }

    @Test
    void testOrderedDocuments() {
        // Given
        LOG.debug("Testing ordered document retrieval for consistent ordering");
        
        // When
        var orderedDocs = testDataHelper.getOrderedSamplePipeDocuments();
        
        // Then - Convert AssertJ to Hamcrest with detailed descriptions
        // AssertJ: assertThat(orderedDocs).isNotEmpty() -> Hamcrest: assertThat("Ordered documents should not be empty", orderedDocs, is(not(empty())))
        assertThat("Ordered documents should not be empty", orderedDocs, is(not(empty())));

        // Verify ordering is consistent
        if (orderedDocs.size() > 1) {
            String firstId = orderedDocs.get(0).getDocId();
            String secondId = orderedDocs.get(1).getDocId();
            
            LOG.debugf("Comparing document order - first ID: %s, second ID: %s", firstId, secondId);

            // IDs should be consistently ordered
            // AssertJ: assertThat(firstId.compareTo(secondId)).isLessThan(0) -> Hamcrest: assertThat("First document ID should be lexicographically before second", firstId.compareTo(secondId), is(lessThan(0)))
            assertThat("First document ID should be lexicographically before second", firstId.compareTo(secondId), is(lessThan(0)));
        }
        
        LOG.debugf("Ordered documents test completed - total documents: %d", orderedDocs.size());
    }

    @Test
    void testGetDocumentByIndex() {
        // Given
        LOG.debug("Testing document retrieval by specific index");
        
        // When
        var orderedDocs = testDataHelper.getOrderedSamplePipeDocuments();

        if (orderedDocs.size() > 5) {
            LOG.debug("Testing document retrieval at indices 0 and 5");
            
            // Test retrieving specific documents by index
            PipeDoc doc0 = testDataHelper.getSamplePipeDocByIndex(0);
            PipeDoc doc5 = testDataHelper.getSamplePipeDocByIndex(5);

            // Then - Convert AssertJ to Hamcrest with detailed descriptions
            // AssertJ: assertThat(doc0).isNotNull() -> Hamcrest: assertThat("Document at index 0 should not be null", doc0, is(notNullValue()))
            assertThat("Document at index 0 should not be null", doc0, is(notNullValue()));
            
            // AssertJ: assertThat(doc5).isNotNull() -> Hamcrest: assertThat("Document at index 5 should not be null", doc5, is(notNullValue()))
            assertThat("Document at index 5 should not be null", doc5, is(notNullValue()));
            
            // AssertJ: assertThat(doc0.getDocId()).isNotEqualTo(doc5.getDocId()) -> Hamcrest: assertThat("Documents at different indices should have different IDs", doc0.getDocId(), is(not(equalTo(doc5.getDocId()))))
            assertThat("Documents at different indices should have different IDs", doc0.getDocId(), is(not(equalTo(doc5.getDocId()))));
            
            LOG.debugf("Document by index test completed - doc0 ID: %s, doc5 ID: %s", doc0.getDocId(), doc5.getDocId());
        } else {
            LOG.debugf("Skipping index test - only %d documents available (need > 5)", orderedDocs.size());
        }
    }

    @Test
    @org.junit.jupiter.api.Disabled("Disabled due to missing test data files")
    void testPipelineGeneratedDocuments() {
        // Test loading pipeline-generated documents from different stages
        var stages = testDataHelper.getPipelineStages();

        if (!stages.isEmpty()) {
            LOG.infof("Found %d pipeline stages: %s", stages.size(), stages);

            for (String stage : stages) {
                Collection<PipeDoc> stageDocs = testDataHelper.getPipelineGeneratedDocuments(stage);
                LOG.infof("Stage '%s' has %d documents", stage, stageDocs.size());
            }
        } else {
            LOG.info("No pipeline-generated documents available");
        }
    }

    @Test
    void testVariousDocumentTypes() {
        // Test loading various specialized document types

        // Tika request/response documents
        var tikaRequests = testDataHelper.getTikaRequestDocuments();
        var tikaResponses = testDataHelper.getTikaResponseDocuments();
        LOG.infof("Tika requests: %d, responses: %d", 
                tikaRequests.size(), tikaResponses.size());

        // Chunker input/output
        var chunkerInput = testDataHelper.getChunkerInputDocuments();
        var chunkerOutput = testDataHelper.getChunkerOutputStreams();
        LOG.infof("Chunker input: %d docs, output: %d streams", 
                chunkerInput.size(), chunkerOutput.size());

        // Embedder documents
        var embedderInput = testDataHelper.getEmbedderInputDocuments();
        var embedderOutput = testDataHelper.getEmbedderOutputDocuments();
        LOG.infof("Embedder input: %d, output: %d", 
                embedderInput.size(), embedderOutput.size());
    }

    @Test
    void testDataConsistency() {
        // Given
        LOG.debug("Testing data consistency between collections and maps");
        
        // When
        var docs = testDataHelper.getSamplePipeDocuments();
        var docsMap = testDataHelper.getSamplePipeDocumentsMap();

        // Then - Convert AssertJ to Hamcrest with detailed descriptions
        // AssertJ: assertThat(docsMap).hasSameSizeAs(docs) -> Hamcrest: assertThat("Document map should have same size as collection", docsMap.size(), is(docs.size()))
        assertThat("Document map should have same size as collection", docsMap.size(), is(docs.size()));
        
        LOG.debugf("Verifying consistency - collection size: %d, map size: %d", docs.size(), docsMap.size());

        // All documents in collection should be in map
        for (PipeDoc doc : docs) {
            // AssertJ: assertThat(docsMap).containsKey(doc.getDocId()) -> Hamcrest: assertThat("Document map should contain document ID", docsMap, hasKey(doc.getDocId()))
            assertThat("Document map should contain document ID", docsMap, hasKey(doc.getDocId()));
            
            // AssertJ: assertThat(docsMap.get(doc.getDocId())).isEqualTo(doc) -> Hamcrest: assertThat("Document from map should equal document from collection", docsMap.get(doc.getDocId()), is(equalTo(doc)))
            assertThat("Document from map should equal document from collection", docsMap.get(doc.getDocId()), is(equalTo(doc)));
        }
        
        LOG.debugf("Data consistency test completed - all %d documents verified", docs.size());
    }
// }
